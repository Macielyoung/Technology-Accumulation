## 知识图谱应用于推荐系统

**推荐系统的任务和难点**

推荐系统一般可以分成两类：一类是评分预测（rating prediction），比如电影评分，表达用户对电影的喜好程度，这种信息也叫显示反馈（explicit feedback）；另一类是点击率预测（click-through rate prediction），例如新闻类应用中，系统需要预测用户点击某新闻的概率来优化推荐方案，这种场景下的用户反馈信息只能表达用户的行为特征，而不能反映用户的喜好程度，这种信息称为隐式反馈（implicit feedback）。

![](https://github.com/Macielyoung/Technology-Accumulation/blob/master/Knowledge%20Graph/pic/RS.png)

传统的推荐系统只使用用户和物品的历史交互信息（显式或隐式反馈）作为输入，这会带来两个问题：一、实际场景中，用户和物品的交互信息往往是非常稀疏的。如电影类APP中可能有上万部电影，而一个用户打过分的电影可能也就十几部，使用如此少量的观测数据来预测大量的未知信息，会极大增加算法的过拟合风险；二、对于新加入的用户商品，由于没有历史信息，无法准确进行建模和推荐，这种称为冷启动问题（cold start）。

解决稀疏性和冷启动问题一个常见思路就是引入一些辅助信息输入。辅助信息包括：

- 社交网络（social networks）：一个用户对某个物品感兴趣，他的朋友可能也会对该物品感兴趣；
- 用户/物品属性（attributes）：拥有同种属性的用户可能会对同一类物品感兴趣；
- 图像/视频/音频/文本等多媒体信息（multimedia）：例如商品图片、电影预告片、音乐、新闻标题等；
- 上下文（context）：用户-物品交互的时间、地点、当前会话信息等。



**知识图谱引入推荐系统**

![](https://github.com/Macielyoung/Technology-Accumulation/blob/master/Knowledge%20Graph/pic/KG.jpg)

知识图谱是一种语义网络，节点代表实体，边代表实体之间的各种语义关系。一个知识图谱由若干个三元组（h，r，t）组成，其中h，t是关系的头、尾节点，r代表关系。

知识图谱的引入可以让推荐结果更加具有以下特征：

* 精确性（precision）。知识图谱为物品引入了更多的语义关系，可以深层次地发现用户兴趣；
* 多样性（diversity）。知识图谱提供了不同的关系连接种类，有利于推荐结果的发散，避免推荐结果局限于单一类型；
* 可解释性（explainability）。知识图谱可以连接用户的历史记录和推荐结果，从而提高用户对推荐结果的满意度和接受度，增强用户对推荐系统的信任。

现有工作主要分两类：

* 以**LibFM[1]**为代表的通用的基于特征的推荐方法（generic feature-based methods）。
* 以**PER [2]**、**MetaGraph[3]**为代表的基于路径的推荐方法（path-based methods）。



**知识图谱特征学习**

知识图谱特征学习（Knowledge Graph Embedding）为知识图谱的每个实体和关系学习得到一个低位向量，同时保持图中原有的结构或语义信息。知识图谱特征学习模型分两类：

- 基于距离的翻译模型（distance-based translational models）。这类模型使用基于距离的评分函数评估三元组的概率，将尾节点视为头结点和关系翻译得到的结果。这类方法的代表有TransE、TransH、TransR等；

![](https://github.com/Macielyoung/Technology-Accumulation/blob/master/Knowledge%20Graph/pic/dis-based.png)

* 基于语义的匹配模型（semantic-based matching models）。这类模型使用基于相似度的评分函数评估三元组的概率，将实体和关系映射到隐语义空间中进行相似度度量。这类方法的代表有SME、NTN、MLP、NAM等。

![](https://github.com/Macielyoung/Technology-Accumulation/blob/master/Knowledge%20Graph/pic/semantic-based.png)

知识图谱特征学习为每个实体和特征学习得到了一个低维向量，而且在向量中保持了原图的结构和语义信息，所以一组好的实体向量可以充分且完全地表示实体之间的相互关系。

知识图谱特征学习可以：

- 降低知识图谱的高维性和异构性；
- 增强知识图谱应用的灵活性；
- 减轻特征工程的工作量；
- 减少由于引入知识图谱带来的额外计算负担。



**知识图谱特征学习应用到推荐系统的学习方式**

将知识图谱作为辅助信息引入到推荐系统中可以有效地解决传统推荐系统存在的稀疏性和冷启动问题。目前，将知识图谱特征学习应用到推荐系统中主要通过三种方式——**依次学习、联合学习和交替学习**。

* 依次学习（one-by-one learning）。首先使用知识图谱特征学习得到实体向量和关系向量，然后将这些低维向量引入推荐系统，学习得到用户向量和物品向量；

  ![](https://github.com/Macielyoung/Technology-Accumulation/blob/master/Knowledge%20Graph/pic/onebyone%20learning.jpg)

* 联合学习（joint learning）。将知识图谱特征学习和推荐算法的目标函数结合，使用端到端的方法进行联合学习；

  ![](https://github.com/Macielyoung/Technology-Accumulation/blob/master/Knowledge%20Graph/pic/joint%20learning.jpg)

* 交替学习（alternate learning）。将知识图谱特征学习和推荐算法视为两个分离但又相关的任务，使用多任务学习（multi-task learning）的框架进行交替学习。

  ![](https://github.com/Macielyoung/Technology-Accumulation/blob/master/Knowledge%20Graph/pic/alternate%20learning.jpg)



**依次学习**

以**新闻推荐[4]**为例来介绍依次学习。首先需要提取知识图谱特征，该步骤的方法如下：

（1）实体连接（entity linking）。从文本中发现相关词汇，并与知识图谱中的实体进行匹配。

（2）知识图谱构建。根据匹配的实体，抽取子图。子图的大小会影响后续算法的运行时间和效果；越大的子图通常会学习更好的特征，但所需运行时间更长。

（3）知识图谱特征学习。使用知识图谱特征学习算法（如TransE等）学习得到关系和实体向量。

![](https://github.com/Macielyoung/Technology-Accumulation/blob/master/Knowledge%20Graph/pic/learning%20steps.jpg)

为了刻画实体，使用一个实体的上下文实体特征（contextual entity embeddings）。一个实体e的上下文实体是e的所有一跳邻居节点，e的上下文实体特征是e的所有上下文实体特征的平均值：

					$$context(e) = {e_{i}|(e, r, e_{i}) \in G or (e_{i}, r, e) \in G}$$
	
							$$\bar{e} = \frac{1}{\left | context(e) \right |}\sum_{e_{i} \in context(e)} e_{i}$$

得到实体特征后，第二步是构建推荐模型，该模型是一个基于CNN和注意力机制的新闻推荐方法：

* 基于卷积神经网络的文本特征提取：将新闻标题的词向量（word embedding）、实体向量（entity embedding）和实体上下文向量（context embedding）作为多个通道（类似于图像中红黄蓝三通道），在CNN下进行融合。
* 基于注意力机制的用户历史兴趣融合：在判断用户对当前新闻的兴趣时，使用注意力网络（attention network）给用户历史记录分配不同的权重。

![](https://github.com/Macielyoung/Technology-Accumulation/blob/master/Knowledge%20Graph/pic/CNNAttention.jpg)

**依次学习的优势在于知识图谱特征学习模块和推荐系统模块相互独立**。在真实场景中，特别是知识图谱很大的情况下，进行一次知识图谱特征学习的时间开销会很大，而一般而言，知识图谱远没有推荐模块更新地快。因此我们可以先通过一次训练得到实体和关系向量，以后每次推荐系统模块需要更新时都可以直接使用这些向量作为输入，而无需重新训练。

**依次学习的缺点**也正在于此：因为两个模块相互独立，所以**无法做到端到端的训练**。通常来说，知识图谱特征学习得到的向量会更适合于知识图谱内的任务，比如连接预测、实体分类等，并非完全适合特定的推荐任务。在缺乏推荐模块的监督信号的情况下，学习得到的实体向量是否真的对推荐任务有帮助，还需要通过进一步的实验来推断。



**联合学习**

联合学习的核心是将推荐算法和知识图谱特征学习的目标融合，并在一个端到端的优化目标中进行训练。我们以**CKE[5]**和**Ripple Network[6]**为例介绍联合学习。

推荐系统中存在着很多与知识图谱相关的信息，以电影推荐为例：

* 结构化知识（structural knowledge），例如导演、类别等；
* 图像知识（visual knowledge），例如海报，剧照等；
* 文本知识（textual knowledge），例如电影描述、影评等。

**Collaborative Knowledge base Embedding（CKE）**

CKE是一个基于协同过滤和知识图谱特征学习的推荐系统：

![](E:\github\Technology-Accumulation\Knowledge Graph\pic\CKE.jpg)

CKE使用如下方式进行三种知识的学习：

* 结构化知识学习：TransR。TransR是一种基于距离的翻译模型，可以学习得到知识实体的向量表示；
* 文本知识学习：去噪自编码器。去噪自编码器可以学习得到文本的一种泛化能力较强的向量表示；

![](E:\github\Technology-Accumulation\Knowledge Graph\pic\denosing autoencoder.jpg)

* 图像知识学习：卷积-反卷积自编码器。卷积-反卷积自编码器可以得到图像的一种泛化能力较强的向量表示。

![](E:\github\Technology-Accumulation\Knowledge Graph\pic\convEncoder.jpg)

将三种知识学习的目标函数与推荐系统中的协同过滤结合，得到如下联合损失函数：

![](E:\github\Technology-Accumulation\Knowledge Graph\pic\loss.jpg)

**Ripple Network**

Ripple Network模拟了用户兴趣在知识图谱上的传播过程，整个过程类似于水波的传播：

* 一个用户的兴趣以其历史记录中的实体为中心，在知识图谱上向外逐层扩散；
* 一个用户的兴趣在知识图谱上的扩散过程中逐渐衰减。

下图展示Ripple Network的模型。对于给定的用户u和物品v，我们将历史相关实体集合V中的所有实体进行相似度计算，并利用计算得到的权重值对V中实体在知识图谱中对应的尾结点进行加权求和。求和得到的结果可以视为v在u的一跳相关实体中的一个响应。该过程可以重复在u的二跳、三跳相关实体中进行。如此，v在知识图谱上便以V为中心逐层向外扩散。

![](E:\github\Technology-Accumulation\Knowledge Graph\pic\ripple network.jpg)

联合学习的优劣势正好与依次学习相反。**联合学习是一种端到端的训练方式**，推荐系统模块的监督信号可以反馈到知识图谱特征学习中，这对于提高最终的性能是有利的。但是需要注意的是，两个模块在最终的目标函数中结合方式以及权重的分配都需要精细的实验才能确定。**联合学习潜在的问题是训练开销较大，特别是一些使用到图算法的模型**。



**参考文献**

[1] Factorization machines with libfm

[2] Personalized entity recommendation: A heterogeneous information network approach

[3] Meta-graph based recommendation fusion over heterogeneous information networks

[4] DKN: Deep Knowledge-Aware Network for News Recommendation.

[5] Collaborative knowledge base embedding for recommender systems.

[6] Ripple Network: Propagating User Preferences on the Knowledge Graph for Recommender Systems.