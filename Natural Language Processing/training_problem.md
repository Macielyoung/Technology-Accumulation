## 训练NN模型问题

### 模型欠拟合

最近在训练一个transformer模型用于多分类任务时，发现刚开始几个epoch时loss可以下降，然后就几乎没有变化，模型准确率也维持在0.2左右无法上升，测试集中的准确率也很低，这是典型的欠拟合。

如果使用同样的数据模型能够缓慢的提升准确率，而在大样本数据中无法全部拟合，这种情况属于神经网络拟合能力不足。对于这种情况可以增加神经网络的宽度或者深度，增加深度较优。

如果使用同样数据模型仍然无法提升准确率，则可能是其他因素。

（1）寻找最优权重初始化。主要分三类：均匀分布、正太分布和相同固定值。全0的初始化，一般只会被用于逻辑斯蒂回归之类的这种二分类问题上，最多是浅层的神经网络上。接近于0的均匀分布会导致梯度消失，使得训练时的loss难以收敛。

（2）使用适当的激活函数。只有神经网络的输出层，使用全连接层来分类的情况下才会使用softmax函数。

（3）选择合适的优化器和学习速率。



### 训练集Loss无法下降

训练集Loss无法下降：

1. 权重初始化有问题。
2. 过度正则化。
3. 选择合适的激活函数和损失函数
4. 选择合适的优化器和学习速率
5. batch size过大。batch size过小，会导致模型后期摇摆不定，迟迟难以收敛，而过大时，模型前期由于梯度的平均，导致收敛速度过慢。
6. 数据集未打散
7. 未进行归一化

验证集Loss无法下降：

验证集无法下降主要由于过拟合，毕竟数据和训练集同分布。而过拟合的解决方法主要就是正则化、归一化、对数据扰动扩增等一些策略。

测试集Loss无法下降：

测试集的问题主要可能是数据样本场景不一致以及一些噪声问题。比如我们训练的文本分类中文本都是一些比较标准规范的自然语句，而测试集则是用户输入的一些语句，这类样本中有些并不符合语法规范，另外可能存在各种拼写、噪音等错误，所以我们可以在训练集上增加噪声扰动或者对测试集进行一个预处理。

