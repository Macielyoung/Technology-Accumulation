## 大数据Top K思路

**问题描述**

在大规模数据中，常出现一类问题，在海量数据中找出出现频率最高的K个数，或者从海量数据中找出最大的前K个数，这类问题称为“Top K”问题。现实应用场景如：在搜素引擎中搜索最热门的10个搜索词；在歌曲库中统计下载率最高的前10首歌等等。



有1亿个浮点数，如何求得其中最大的10000个数？

**解决方案**

1. 第一种方法就是对所有数据排序，然后在排序后的数据中查找。最快的排序算法时间复杂度是O(nlogn)，如快排。不过该方法并不高效，需求中仅仅需要最大的K个数，而该方法把所有数据都排序好了，浪费时间空间。
2. 第二种方法是局部淘汰法。用一个容器保存前10000个数，然后用剩余的元素和容器中的最小的元素进行比较，如果后续元素比最小数字大，则替换。此时时间复杂度为O(n+m^2)，m为容器大小。
3. 第三种方法是分治法。将1亿个数据分成100份，每份100万个数据，找到每份数据中前1万大的数据，然后再在这100*1万个数据中找出最大的1万个数据。100万个数据查找最大1万数据方法：使用快排的方法，将数据分成两堆，如果大的那堆大于1万个数据，则继续对大堆执行快排分割；如果大堆数据小于1万，就在小堆数据中执行快排划分，找出10000-m个数据。找到前100万大的数据后，再执行同样的思路查找前1万大的数据，这种方法需要的内存空间大小为10^6 * 4=4M，共需要101次这样的操作。
4. 第四种方法是哈希法。若1亿个数据中有很多重复的数，可以通过哈希法来去重，如果重复率很高的话，可以减少很大内存容量，然后再通过分治法或最小堆法来查找前K个数。
5. 第五种方法是最小堆法。用前10000个数构建一个最小堆，建堆时间复杂度为O(mlogm)，m为堆的大小。然后遍历后续的数字，和堆顶元素进行比较，如果比它大，则替换该元素并重新调整堆为最小堆。该方法时间复杂度为O(nmlogm)，空间复杂度为10000，O(1)。



**实际运行**

针对不同的应用场景，分析不同的适用方案。

1. 单机+单核+足够内存。如果每个查询词占8B，则共需内存10^9 * 8=8G，内存足够则可直接在内存中进行排序，直接查找。
2. 单机+多核+足够内存。由于有多核，可以使用hash法将数据划分到多个群组，每个群组由一个线程处理，最后一个线程归并。该方法可能出现数据倾斜的问题，即处理快的进程需要等待慢的进程，时间有最慢的进程来决定，解决方法是把数据分成c*n个群组，让处理快的进程主动获取下一个群组数据继续处理，直至所有数据被处理完。
3. 单机+单核+受限内存。使用哈希法分割原始文件，直至每个文件中的数据小于内存大小，这样每个文件即可放入内存中处理，可采用方案1来解决。
4. 多机+受限内存。将数据分发到多台机器上，每台机器采用方案3来解决本地数据。