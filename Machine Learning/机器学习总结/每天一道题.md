## 机器学习每日一题

**梯度下降法**

梯度下降法的正确步骤是什么？   （D）

a. 计算预测值和真实值之间的误差

b. 重复迭代，直至得到网络权重的最佳值

c. 把输入传入网络，得到输出值

d. 用随机值初始化权重和偏差

e. 对每一个产生误差的神经元，调整相应的权重值以减小误差

A. abcde               B. edcba               C. cbaed                D. dcaeb



**逻辑回归（LR）**

关于逻辑回归和SVM，下面说法错误的是？         （B）

A. Logistic回归可用于预测事件发生概率的大小 

B. Logistic回归的目标函数是最小化后验概率 

C. SVM的目标的结构风险最小化 

D. SVM可以有效避免模型过拟合

解析：Logit回归本质上是一种根据样本对权值进行**极大似然估计**的方法，而后验概率正比于先验概率和似然函数的乘积。logit仅仅是最大化似然函数，并没有最大化后验概率，更谈不上最小化后验概率，B错误。A. Logit回归的输出就是样本属于正类别的几率，可以计算出概率。C. SVM的目标是找到使得训练数据尽可能分开且分类间隔最大的超平面，应该属于结构风险最小化. D. SVM可以通过正则化系数控制模型的复杂度，避免过拟合。 



**SVM**

下列选项不是SVM核函数的是                   （B）

A. 多项式核函数

B. logistic核函数

C. 径向基核函数

D. Sigmoid核函数



**聚类算法**

在有监督学习中，我们如何使用聚类算法           （B）

1. 我们可以先创建聚类类别，然后在每个类别上用监督学习分别进行学习

2. 我们可以使用聚类“类别id”作为一个新的特征项，然后再用监督学习分别进行学习

3. 在进行监督学习之前，我们不能新建聚类类别

4. 我们不可以使用聚类“类别id”作为一个新的特征项，然后再用监督学习分别进行学习

A. 2和4

B. 1和2

C. 3和4

D. 1和3



**特征降维**

下列方法中，不可以用于特征降维的方法包括。     （E）

A 主成分分析PCA

B 线性判别分析LDA

C 深度学习SparseAutoEncoder

D 矩阵奇异值分解SVD

E 最小二乘法LeastSquares

【解析】

A.特征降维方法主要有：PCA，LLE，Isomap

B.LDA:线性判别分析，可用于降维

C.稀疏自编码就是用少于输入层神经元数量的隐含层神经元去学习表征输入层的特征，相当于把输入层的特征压缩了，所以是特征降维。

D.SVD和PCA类似，也能看成一种降维方法



想要减少数据集中的特征数, 即降维，以下哪些方案适合:       （D）

1. 使用前向特征选择方法

2. 使用后向特征排除方法

3. 我们先把所有特征都使用, 去训练一个模型, 得到测试集上的表现. 然后去掉一个特征, 再去训练, 用交叉验证看看测试集上的表现. 如果表 现比原来还要好, 我们可以去除这个特征.

4. 查看相关性表, 去除相关性最高的一些特征

A. 1、2

B. 2、3、4

C. 1、2、4

D. All